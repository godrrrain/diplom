{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c82f55-f854-436e-a9d8-e4c4596699b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/banan/anaconda3/envs/syft_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syft is imported\n"
     ]
    }
   ],
   "source": [
    "# run this cell\n",
    "try:\n",
    "    import syft as sy\n",
    "    print(\"Syft is imported\")\n",
    "except:\n",
    "    print(\"Syft is not installed. Please use the 🧙🏽‍♂️ Install Wizard above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b833cc0-288a-4d04-a9b3-7347e68e9cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING:\u001b[0m CHANGE YOUR USERNAME AND PASSWORD!!! \n",
      "\n",
      "Anyone can login as an admin to your node right now because your password is still the default PySyft username and password!!!\n",
      "\n",
      "Connecting to localhost... done! \t Logging into default_node_name... done!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    domain_client = sy.login(\n",
    "       port=8082,\n",
    "       email=\"info@openmined.org\",\n",
    "       password=\"changethis\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Unable to login. Please check your domain is up with `!hagrid check localhost:8081 --timeout=120`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e661c8c3-8232-4aca-bea8-17cf61392166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./anaconda3/envs/syft_env/lib/python3.9/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./anaconda3/envs/syft_env/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c14ac6a-4c0d-4b9c-9575-f52525325390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('Cancer_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2479f46-0f04-4ba1-bd4a-9f342cca7b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5965e528-3b6a-4306-8c08-f83751927f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a90f21-77fb-491d-8165-c9fc78c56810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset1 = dataset.drop([\"Unnamed: 32\"],axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded924d3-84f3-48d3-94a5-d92764d977b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bbd68d-a6db-47e4-ab6b-8774874015d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c78d11-fa4e-44bd-b8ee-09ecc4d9a75d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data is of type: <class 'pandas.core.frame.DataFrame'>\n",
      "raw_data is of type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f'raw_data is of type: {type(dataset1)}')\n",
    "print(f'raw_data is of type: {type(dataset1.values)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7acb89a-99e3-4b90-8c46-7da0fbdd4535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      17.99\n",
       "1      20.57\n",
       "2      19.69\n",
       "3      11.42\n",
       "4      20.29\n",
       "       ...  \n",
       "564    21.56\n",
       "565    20.13\n",
       "566    16.60\n",
       "567    20.60\n",
       "568     7.76\n",
       "Name: radius_mean, Length: 569, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[\"radius_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070cdf08-5c42-4cfa-9f64-6d39ee56b739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor annotated with DP Metadata!\n",
      "You can upload this Tensor to a domain node by calling `<domain_client>.load_dataset` and passing in this tensor as an asset.\n",
      "Tensor annotated with DP Metadata!\n",
      "You can upload this Tensor to a domain node by calling `<domain_client>.load_dataset` and passing in this tensor as an asset.\n"
     ]
    }
   ],
   "source": [
    "final_dataset = dict()\n",
    "\n",
    "data_subjects = sy.DataSubjectArray.from_objs(dataset1[\"id\"])\n",
    "\n",
    "final_dataset[\"radius_mean\"] = sy.Tensor(dataset1[\"radius_mean\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=0, upper_bound=100, data_subject=data_subjects\n",
    ")\n",
    "\n",
    "final_dataset[\"texture_mean\"] = sy.Tensor(dataset1[\"radius_mean\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=0, upper_bound=100, data_subject=data_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b266bc4-75a7-4daf-8bec-b8725d9a7423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'radius_mean': Tensor(child=PhiTensor(child=[17.99  20.57  19.69  11.42  20.29  12.45  18.25  13.71  13.    12.46\n",
       "  16.02  15.78  19.17  15.85  13.73  14.54  14.68  16.13  19.81  13.54\n",
       "  13.08   9.504 15.34  21.16  16.65  17.14  14.58  18.61  15.3   17.57\n",
       "  18.63  11.84  17.02  19.27  16.13  16.74  14.25  13.03  14.99  13.48\n",
       "  13.44  10.95  19.07  13.28  13.17  18.65   8.196 13.17  12.05  13.49\n",
       "  11.76  13.64  11.94  18.22  15.1   11.52  19.21  14.71  13.05   8.618\n",
       "  10.17   8.598 14.25   9.173 12.68  14.78   9.465 11.31   9.029 12.78\n",
       "  18.94   8.888 17.2   13.8   12.31  16.07  13.53  18.05  20.18  12.86\n",
       "  11.45  13.34  25.22  19.1   12.    18.46  14.48  19.02  12.36  14.64\n",
       "  14.62  15.37  13.27  13.45  15.06  20.26  12.18   9.787 11.6   14.42\n",
       "  13.61   6.981 12.18   9.876 10.49  13.11  11.64  12.36  22.27  11.34\n",
       "   9.777 12.63  14.26  10.51   8.726 11.93   8.95  14.87  15.78  17.95\n",
       "  11.41  18.66  24.25  14.5   13.37  13.85  13.61  19.    15.1   19.79\n",
       "  12.19  15.46  16.16  15.71  18.45  12.77  11.71  11.43  14.95  11.28\n",
       "   9.738 16.11  11.43  12.9   10.75  11.9   11.8   14.95  14.44  13.74\n",
       "  13.     8.219  9.731 11.15  13.15  12.25  17.68  16.84  12.06  10.9\n",
       "  11.75  19.19  19.59  12.34  23.27  14.97  10.8   16.78  17.47  14.97\n",
       "  12.32  13.43  15.46  11.08  10.66   8.671  9.904 16.46  13.01  12.81\n",
       "  27.22  21.09  15.7   11.41  15.28  10.08  18.31  11.71  11.81  12.3\n",
       "  14.22  12.77   9.72  12.34  14.86  12.91  13.77  18.08  19.18  14.45\n",
       "  12.23  17.54  23.29  13.81  12.47  15.12   9.876 17.01  13.11  15.27\n",
       "  20.58  11.84  28.11  17.42  14.19  13.86  11.89  10.2   19.8   19.53\n",
       "  13.65  13.56  10.18  15.75  13.27  14.34  10.44  15.    12.62  12.83\n",
       "  17.05  11.32  11.22  20.51   9.567 14.03  23.21  20.48  14.22  17.46\n",
       "  13.64  12.42  11.3   13.75  19.4   10.48  13.2   12.89  10.65  11.52\n",
       "  20.94  11.5   19.73  17.3   19.45  13.96  19.55  15.32  15.66  15.53\n",
       "  20.31  17.35  17.29  15.61  17.19  20.73  10.6   13.59  12.87  10.71\n",
       "  14.29  11.29  21.75   9.742 17.93  11.89  11.33  18.81  13.59  13.85\n",
       "  19.16  11.74  19.4   16.24  12.89  12.58  11.94  12.89  11.26  11.37\n",
       "  14.41  14.96  12.95  11.85  12.72  13.77  10.91  11.76  14.26  10.51\n",
       "  19.53  12.46  20.09  10.49  11.46  11.6   13.2    9.    13.5   13.05\n",
       "  11.7   14.61  12.76  11.54   8.597 12.49  12.18  18.22   9.042 12.43\n",
       "  10.25  20.16  12.86  20.34  12.2   12.67  14.11  12.03  16.27  16.26\n",
       "  16.03  12.98  11.22  11.25  12.3   17.06  12.99  18.77  10.05  23.51\n",
       "  14.42   9.606 11.06  19.68  11.71  10.26  12.06  14.76  11.47  11.95\n",
       "  11.66  15.75  25.73  15.08  11.14  12.56  13.05  13.87   8.878  9.436\n",
       "  12.54  13.3   12.76  16.5   13.4   20.44  20.2   12.21  21.71  22.01\n",
       "  16.35  15.19  21.37  20.64  13.69  16.17  10.57  13.46  13.66  11.08\n",
       "  11.27  11.04  12.05  12.39  13.28  14.6   12.21  13.88  11.27  19.55\n",
       "  10.26   8.734 15.49  21.61  12.1   14.06  13.51  12.8   11.06  11.8\n",
       "  17.91  11.93  12.96  12.94  12.34  10.94  16.14  12.85  17.99  12.27\n",
       "  11.36  11.04   9.397 14.99  15.13  11.89   9.405 15.5   12.7   11.16\n",
       "  11.57  14.69  11.61  13.66   9.742 10.03  10.48  10.8   11.13  12.72\n",
       "  14.9   12.4   20.18  18.82  14.86  13.98  12.87  14.04  13.85  14.02\n",
       "  10.97  17.27  13.78  10.57  18.03  11.99  17.75  14.8   14.53  21.1\n",
       "  11.87  19.59  12.    14.53  12.62  13.38  11.63  13.21  13.     9.755\n",
       "  17.08  27.42  14.4   11.6   13.17  13.24  13.14   9.668 17.6   11.62\n",
       "   9.667 12.04  14.92  12.27  10.88  12.83  14.2   13.9   11.49  16.25\n",
       "  12.16  13.9   13.47  13.7   15.73  12.45  14.64  19.44  11.68  16.69\n",
       "  12.25  17.85  18.01  12.46  13.16  14.87  12.65  12.47  18.49  20.59\n",
       "  15.04  13.82  12.54  23.09   9.268  9.676 12.22  11.06  16.3   15.46\n",
       "  11.74  14.81  13.4   14.58  15.05  11.34  18.31  19.89  12.88  12.75\n",
       "   9.295 24.63  11.26  13.71   9.847  8.571 13.46  12.34  13.94  12.07\n",
       "  11.75  11.67  13.68  20.47  10.96  20.55  14.27  11.69   7.729  7.691\n",
       "  11.54  14.47  14.74  13.21  13.87  13.62  10.32  10.26   9.683 10.82\n",
       "  10.86  11.13  12.77   9.333 12.88  10.29  10.16   9.423 14.59  11.51\n",
       "  14.05  11.2   15.22  20.92  21.56  20.13  16.6   20.6    7.76 ], min_vals=<lazyrepeatarray data: [0] -> shape: (569,)>, max_vals=<lazyrepeatarray data: [100] -> shape: (569,)>)),\n",
       " 'texture_mean': Tensor(child=PhiTensor(child=[17.99  20.57  19.69  11.42  20.29  12.45  18.25  13.71  13.    12.46\n",
       "  16.02  15.78  19.17  15.85  13.73  14.54  14.68  16.13  19.81  13.54\n",
       "  13.08   9.504 15.34  21.16  16.65  17.14  14.58  18.61  15.3   17.57\n",
       "  18.63  11.84  17.02  19.27  16.13  16.74  14.25  13.03  14.99  13.48\n",
       "  13.44  10.95  19.07  13.28  13.17  18.65   8.196 13.17  12.05  13.49\n",
       "  11.76  13.64  11.94  18.22  15.1   11.52  19.21  14.71  13.05   8.618\n",
       "  10.17   8.598 14.25   9.173 12.68  14.78   9.465 11.31   9.029 12.78\n",
       "  18.94   8.888 17.2   13.8   12.31  16.07  13.53  18.05  20.18  12.86\n",
       "  11.45  13.34  25.22  19.1   12.    18.46  14.48  19.02  12.36  14.64\n",
       "  14.62  15.37  13.27  13.45  15.06  20.26  12.18   9.787 11.6   14.42\n",
       "  13.61   6.981 12.18   9.876 10.49  13.11  11.64  12.36  22.27  11.34\n",
       "   9.777 12.63  14.26  10.51   8.726 11.93   8.95  14.87  15.78  17.95\n",
       "  11.41  18.66  24.25  14.5   13.37  13.85  13.61  19.    15.1   19.79\n",
       "  12.19  15.46  16.16  15.71  18.45  12.77  11.71  11.43  14.95  11.28\n",
       "   9.738 16.11  11.43  12.9   10.75  11.9   11.8   14.95  14.44  13.74\n",
       "  13.     8.219  9.731 11.15  13.15  12.25  17.68  16.84  12.06  10.9\n",
       "  11.75  19.19  19.59  12.34  23.27  14.97  10.8   16.78  17.47  14.97\n",
       "  12.32  13.43  15.46  11.08  10.66   8.671  9.904 16.46  13.01  12.81\n",
       "  27.22  21.09  15.7   11.41  15.28  10.08  18.31  11.71  11.81  12.3\n",
       "  14.22  12.77   9.72  12.34  14.86  12.91  13.77  18.08  19.18  14.45\n",
       "  12.23  17.54  23.29  13.81  12.47  15.12   9.876 17.01  13.11  15.27\n",
       "  20.58  11.84  28.11  17.42  14.19  13.86  11.89  10.2   19.8   19.53\n",
       "  13.65  13.56  10.18  15.75  13.27  14.34  10.44  15.    12.62  12.83\n",
       "  17.05  11.32  11.22  20.51   9.567 14.03  23.21  20.48  14.22  17.46\n",
       "  13.64  12.42  11.3   13.75  19.4   10.48  13.2   12.89  10.65  11.52\n",
       "  20.94  11.5   19.73  17.3   19.45  13.96  19.55  15.32  15.66  15.53\n",
       "  20.31  17.35  17.29  15.61  17.19  20.73  10.6   13.59  12.87  10.71\n",
       "  14.29  11.29  21.75   9.742 17.93  11.89  11.33  18.81  13.59  13.85\n",
       "  19.16  11.74  19.4   16.24  12.89  12.58  11.94  12.89  11.26  11.37\n",
       "  14.41  14.96  12.95  11.85  12.72  13.77  10.91  11.76  14.26  10.51\n",
       "  19.53  12.46  20.09  10.49  11.46  11.6   13.2    9.    13.5   13.05\n",
       "  11.7   14.61  12.76  11.54   8.597 12.49  12.18  18.22   9.042 12.43\n",
       "  10.25  20.16  12.86  20.34  12.2   12.67  14.11  12.03  16.27  16.26\n",
       "  16.03  12.98  11.22  11.25  12.3   17.06  12.99  18.77  10.05  23.51\n",
       "  14.42   9.606 11.06  19.68  11.71  10.26  12.06  14.76  11.47  11.95\n",
       "  11.66  15.75  25.73  15.08  11.14  12.56  13.05  13.87   8.878  9.436\n",
       "  12.54  13.3   12.76  16.5   13.4   20.44  20.2   12.21  21.71  22.01\n",
       "  16.35  15.19  21.37  20.64  13.69  16.17  10.57  13.46  13.66  11.08\n",
       "  11.27  11.04  12.05  12.39  13.28  14.6   12.21  13.88  11.27  19.55\n",
       "  10.26   8.734 15.49  21.61  12.1   14.06  13.51  12.8   11.06  11.8\n",
       "  17.91  11.93  12.96  12.94  12.34  10.94  16.14  12.85  17.99  12.27\n",
       "  11.36  11.04   9.397 14.99  15.13  11.89   9.405 15.5   12.7   11.16\n",
       "  11.57  14.69  11.61  13.66   9.742 10.03  10.48  10.8   11.13  12.72\n",
       "  14.9   12.4   20.18  18.82  14.86  13.98  12.87  14.04  13.85  14.02\n",
       "  10.97  17.27  13.78  10.57  18.03  11.99  17.75  14.8   14.53  21.1\n",
       "  11.87  19.59  12.    14.53  12.62  13.38  11.63  13.21  13.     9.755\n",
       "  17.08  27.42  14.4   11.6   13.17  13.24  13.14   9.668 17.6   11.62\n",
       "   9.667 12.04  14.92  12.27  10.88  12.83  14.2   13.9   11.49  16.25\n",
       "  12.16  13.9   13.47  13.7   15.73  12.45  14.64  19.44  11.68  16.69\n",
       "  12.25  17.85  18.01  12.46  13.16  14.87  12.65  12.47  18.49  20.59\n",
       "  15.04  13.82  12.54  23.09   9.268  9.676 12.22  11.06  16.3   15.46\n",
       "  11.74  14.81  13.4   14.58  15.05  11.34  18.31  19.89  12.88  12.75\n",
       "   9.295 24.63  11.26  13.71   9.847  8.571 13.46  12.34  13.94  12.07\n",
       "  11.75  11.67  13.68  20.47  10.96  20.55  14.27  11.69   7.729  7.691\n",
       "  11.54  14.47  14.74  13.21  13.87  13.62  10.32  10.26   9.683 10.82\n",
       "  10.86  11.13  12.77   9.333 12.88  10.29  10.16   9.423 14.59  11.51\n",
       "  14.05  11.2   15.22  20.92  21.56  20.13  16.6   20.6    7.76 ], min_vals=<lazyrepeatarray data: [0] -> shape: (569,)>, max_vals=<lazyrepeatarray data: [100] -> shape: (569,)>))}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4715237-96a2-4f36-b197-991bb63de857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... uploading...🚀                                                                                                                                             "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdomain_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m   \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtestDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m   \u001b[49m\u001b[43massets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m   \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOur dataset contains test data. There are 2 columns and 4 rows in our dataset.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/node/domain_client.py:729\u001b[0m, in \u001b[0;36mDomainClient.load_dataset\u001b[0;34m(self, assets, name, description, skip_checks, chunk_size, use_blob_storage, **metadata)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# send each asset to blob storage and pack the results back\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m asset_name, asset \u001b[38;5;129;01min\u001b[39;00m assets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 729\u001b[0m     proxy_obj \u001b[38;5;241m=\u001b[39m \u001b[43mupload_to_s3_using_presigned\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43masset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     proxy_assets[asset_name] \u001b[38;5;241m=\u001b[39m proxy_obj\n\u001b[1;32m    738\u001b[0m dataset_bytes \u001b[38;5;241m=\u001b[39m serialize(proxy_assets, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/node/common/util.py:188\u001b[0m, in \u001b[0;36mupload_to_s3_using_presigned\u001b[0;34m(client, data, chunk_size, asset_name, dataset_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dataset_name)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Step 1 - Convert data to be uploaded to binary\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m binary_dataset: \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    189\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(binary_dataset)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Step 2 - Send a message to PyGrid to inform of the data being uploaded,\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# and get presigned url for each chunk of data being uploaded.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:77\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     Exception(\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# capnp_bytes=True\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(is_serializable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_object2bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# capnp proto\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_type(\u001b[43mis_serializable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object2bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_bytes:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     serialized_data \u001b[38;5;241m=\u001b[39m is_serializable\u001b[38;5;241m.\u001b[39m_object2proto()\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/tensor/tensor.py:635\u001b[0m, in \u001b[0;36mTensor._object2bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# this is how we dispatch correct deserialization of bytes\u001b[39;00m\n\u001b[1;32m    633\u001b[0m tensor_msg\u001b[38;5;241m.\u001b[39mmagicHeader \u001b[38;5;241m=\u001b[39m serde_magic_header(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 635\u001b[0m chunk_bytes(\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchild\u001b[39m\u001b[38;5;124m\"\u001b[39m, tensor_msg)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    637\u001b[0m tensor_msg\u001b[38;5;241m.\u001b[39mpublicShape \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpublic_shape, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# upcast the String class before setting to capnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:77\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     Exception(\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# capnp_bytes=True\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(is_serializable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_object2bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# capnp proto\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_type(\u001b[43mis_serializable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object2bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_bytes:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     serialized_data \u001b[38;5;241m=\u001b[39m is_serializable\u001b[38;5;241m.\u001b[39m_object2proto()\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/tensor/autodp/phi_tensor.py:3957\u001b[0m, in \u001b[0;36mPhiTensor._object2bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3955\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mminVals \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_vals, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3956\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mmaxVals \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_vals, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 3957\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mdataSubject \u001b[38;5;241m=\u001b[39m serialize(\u001b[43mdstonumpyutf8\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_subject\u001b[49m\u001b[43m)\u001b[49m, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3958\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mto_string()\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;66;03m# to pack or not to pack?\u001b[39;00m\n\u001b[1;32m   3960\u001b[0m \u001b[38;5;66;03m# to_bytes = pt_msg.to_bytes()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/adp/data_subject.py:198\u001b[0m, in \u001b[0;36mdstonumpyutf8\u001b[0;34m(data_subject)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdstonumpyutf8\u001b[39m(data_subject: DataSubject) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m--> 198\u001b[0m     name_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mdata_subject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m()\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m     np_bytes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(name_bytes, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint64)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np_bytes\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_string'"
     ]
    }
   ],
   "source": [
    "domain_client.load_dataset(\n",
    "   name=\"testDataset\",\n",
    "   assets=final_dataset,\n",
    "   description=\"Our dataset contains test data. There are 2 columns and 4 rows in our dataset.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2f5312b-ee5d-4ea6-8efd-b08942d7212d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You tried to pass an a tensor of type:<class 'numpy.ndarray'> with child.dtype == object. Syft tensor objects only supports numpy objects of (<class 'numpy.int64'>, <class 'numpy.float64'>, <class 'numpy.bool_'>). Please pass in either the supported types or change the default types in syft/core/tensor/config.py ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m country0 \u001b[38;5;241m=\u001b[39m DataSubject(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Create a Syft tensor\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcountry0_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add DP metadata\u001b[39;00m\n\u001b[1;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mprivate(min_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150000\u001b[39m, data_subject\u001b[38;5;241m=\u001b[39mcountry0)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/tensor/tensor.py:504\u001b[0m, in \u001b[0;36mTensor.__init__\u001b[0;34m(self, child, public_shape, public_dtype)\u001b[0m\n\u001b[1;32m    497\u001b[0m         child \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39mastype(DEFAULT_FLOAT_NUMPY_TYPE)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, (np\u001b[38;5;241m.\u001b[39mndarray, PassthroughTensor, GammaTensor)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(child, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [DEFAULT_INT_NUMPY_TYPE, DEFAULT_FLOAT_NUMPY_TYPE, np\u001b[38;5;241m.\u001b[39mbool_]\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(child, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    503\u001b[0m ):\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou tried to pass an a tensor of type:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(child))\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with child.dtype == \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(child, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Syft tensor objects only supports numpy objects of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEFAULT_INT_NUMPY_TYPE,DEFAULT_FLOAT_NUMPY_TYPE,np\u001b[38;5;241m.\u001b[39mbool_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pass in either the supported types or change the default types in syft/core/tensor/config.py \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m     )\n\u001b[1;32m    514\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchild\u001b[39m\u001b[38;5;124m\"\u001b[39m: child}\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: You tried to pass an a tensor of type:<class 'numpy.ndarray'> with child.dtype == object. Syft tensor objects only supports numpy objects of (<class 'numpy.int64'>, <class 'numpy.float64'>, <class 'numpy.bool_'>). Please pass in either the supported types or change the default types in syft/core/tensor/config.py "
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "\n",
    "# select all of Country 0's data\n",
    "country0_data = dataset1.values[3]\n",
    "\n",
    "\n",
    "# Create a DataSubject corresponding to country1\n",
    "from syft.core.adp.data_subject import DataSubject\n",
    "country0 = DataSubject(name=\"id\")\n",
    "\n",
    "# Create a Syft tensor\n",
    "data = sy.Tensor(country0_data)\n",
    "\n",
    "# Add DP metadata\n",
    "data = data.private(min_val=0, max_val=150000, data_subject=country0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a42a1-c143-4efd-ae09-a86f81d8ab21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2019d3-f34c-4320-8347-374ed31de5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca4863b1-5504-4b73-991e-1504057a5661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  Age\n",
      "0  011   40\n",
      "1  015   39\n",
      "2  022    9\n",
      "3  034    8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    data = {'ID': ['011', '015', '022', '034'],\n",
    "           'Age': [40, 39, 9, 8]}\n",
    "\n",
    "    dataset = pd.DataFrame(data)\n",
    "    print(dataset.head())\n",
    "except Exception:\n",
    "    print(\"Install the latest version of Pandas using the command: !pip install pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77c1f66-24a2-4a93-86ad-4e7dc5f345a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd0a81-d98b-40f4-a618-5e4d4054f9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_subjects = sy.DataSubjectArray.from_objs(dataset[\"ID\"])\n",
    "\n",
    "age_data = sy.Tensor(dataset[\"Age\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=0, upper_bound=100, data_subject=data_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963b1cb-963a-44e8-ba58-9e7052759480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "domain_client.load_dataset(\n",
    "   name=\"Family_Age_Dataset\",\n",
    "   assets={\n",
    "       \"Age_Data\": age_data,\n",
    "   },\n",
    "   description=\"Our dataset contains the Ages of our four Family members with unique ID's. There are 2 columns and 4 rows in our dataset.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d09e4d5-bc16-492d-9a85-4efaed246192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "                #myInput {\n",
       "                  background-position: 10px 12px; /* Position the search icon */\n",
       "                  background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "                  background-color: #bbb;\n",
       "                  width: 98%; /* Full-width */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                  padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  margin-bottom: 12px; /* Add some space below the input */\n",
       "                }\n",
       "\n",
       "                #myTable {\n",
       "                  border-collapse: collapse; /* Collapse borders */\n",
       "                  width: 100%; /* Full-width */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                }\n",
       "\n",
       "                #myTable th, #myTable td {\n",
       "                  text-align: left; /* Left-align text */\n",
       "                  padding: 10px; /* Add padding */\n",
       "                }\n",
       "\n",
       "                #myTable tr {\n",
       "                  /* Add a bottom border to all table rows */\n",
       "                  border-bottom: 1px solid #ddd;\n",
       "                }\n",
       "\n",
       "                #myTable tr.header, #myTable tr:hover {\n",
       "                  /* Add a grey background color to the table header and on hover */\n",
       "                  background-color: #777;\n",
       "                }\n",
       "                </style>\n",
       "\n",
       "                <table id=\"myTable\" style=\"width:1000px\">\n",
       "                  <tr class=\"header\">\n",
       "                    <th style=\"width:30px\">Idx</th>\n",
       "                    <th style=\"width:20%;\">Name</th>\n",
       "                    <th style=\"width:35%;\">Description</th>\n",
       "                    <th style=\"width:20%;\">Assets</th>\n",
       "                    <th style=\"width:300px;\">Id</th>\n",
       "                  </tr>\n",
       "                \n",
       "\n",
       "          <tr>\n",
       "            <td>[0]</td>\n",
       "            <td>Family_Age_Dataset</td>\n",
       "            <td>Our dataset contains the Ages of our four Family members with unique ID's. There are 2 columns and 4 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br /></td>\n",
       "            <td>2515f228-3967-4b88-ae59-df697aad6518</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[1]</td>\n",
       "            <td>Spiderman_Audience_Age_Dataset</td>\n",
       "            <td>Our dataset contains the Ages of people who watched the movie Spiderman in the cinema in Moscow. There are 2 columns and 11 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br /></td>\n",
       "            <td>0969b9b9-af47-41e3-9604-4eeb9f16c4bb</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        <script>\n",
       "        function myFunction() {\n",
       "          // Declare variables\n",
       "          var input, filter, table, tr, td, i, txtValue;\n",
       "          input = document.getElementById(\"myInput\");\n",
       "          filter = input.value.toUpperCase();\n",
       "          table = document.getElementById(\"myTable\");\n",
       "          tr = table.getElementsByTagName(\"tr\");\n",
       "\n",
       "          // Loop through all table rows, and hide those who don't match the search query\n",
       "          for (i = 0; i < tr.length; i++) {\n",
       "            name_td = tr[i].getElementsByTagName(\"td\")[1];\n",
       "            desc_td = tr[i].getElementsByTagName(\"td\")[2];\n",
       "            asset_td = tr[i].getElementsByTagName(\"td\")[3];\n",
       "            id_td = tr[i].getElementsByTagName(\"td\")[4];\n",
       "            if (name_td || desc_td || asset_td || id_td) {\n",
       "              name_txtValue = name_td.textContent || name_td.innerText;\n",
       "              desc_txtValue = desc_td.textContent || name_td.innerText;\n",
       "              asset_txtValue = asset_td.textContent || name_td.innerText;\n",
       "              id_txtValue = id_td.textContent || name_td.innerText;\n",
       "              name_bool = name_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              desc_bool = desc_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              asset_bool = asset_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              id_bool = id_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              if (name_bool || desc_bool || asset_bool || id_bool) {\n",
       "                tr[i].style.display = \"\";\n",
       "              } else {\n",
       "                tr[i].style.display = \"none\";\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.DatasetRequestAPI at 0x7f3e09b86850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_client.datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e04ea98-c09d-4a68-9e83-f9f8bbea97e4",
   "metadata": {},
   "source": [
    "Добавим второй датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1acb8c-80fe-4496-9aff-f8da56e00a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  Age\n",
      "0  001   38\n",
      "1  004   28\n",
      "2  005   21\n",
      "3  009   19\n",
      "4  011   18\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    data = {'ID': ['001', '004', '005', '009', '011', '018', '022', '023', '026', '029', '034'],\n",
    "           'Age': [38, 28, 21, 19, 18, 17, 17, 17, 16, 15, 12]}\n",
    "\n",
    "    dataset = pd.DataFrame(data)\n",
    "    print(dataset.head())\n",
    "except Exception:\n",
    "    print(\"Install the latest version of Pandas using the command: !pip install pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4788f2e0-bb64-4c9d-90b7-3bf19d99d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor annotated with DP Metadata!\n",
      "You can upload this Tensor to a domain node by calling `<domain_client>.load_dataset` and passing in this tensor as an asset.\n"
     ]
    }
   ],
   "source": [
    "data_subjects = sy.DataSubjectArray.from_objs(dataset[\"ID\"])\n",
    "\n",
    "age_data = sy.Tensor(dataset[\"Age\"]).annotate_with_dp_metadata(\n",
    "   lower_bound=0, upper_bound=100, data_subject=data_subjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ba410a-d105-4f3e-8d31-23cd32181139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... uploading...🚀                                                                                                                                             "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdomain_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m   \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpiderman_Age_v2_Dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m   \u001b[49m\u001b[43massets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge_Data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m   \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m   \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOur dataset contains the Ages of people who watched the movie Spiderman in the cinema in Moscow version 2. There are 2 columns and 11 rows in our dataset.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/node/domain_client.py:729\u001b[0m, in \u001b[0;36mDomainClient.load_dataset\u001b[0;34m(self, assets, name, description, skip_checks, chunk_size, use_blob_storage, **metadata)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# send each asset to blob storage and pack the results back\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m asset_name, asset \u001b[38;5;129;01min\u001b[39;00m assets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 729\u001b[0m     proxy_obj \u001b[38;5;241m=\u001b[39m \u001b[43mupload_to_s3_using_presigned\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43masset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     proxy_assets[asset_name] \u001b[38;5;241m=\u001b[39m proxy_obj\n\u001b[1;32m    738\u001b[0m dataset_bytes \u001b[38;5;241m=\u001b[39m serialize(proxy_assets, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/node/common/util.py:188\u001b[0m, in \u001b[0;36mupload_to_s3_using_presigned\u001b[0;34m(client, data, chunk_size, asset_name, dataset_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(dataset_name)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Step 1 - Convert data to be uploaded to binary\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m binary_dataset: \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    189\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(binary_dataset)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Step 2 - Send a message to PyGrid to inform of the data being uploaded,\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# and get presigned url for each chunk of data being uploaded.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:77\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     Exception(\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# capnp_bytes=True\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(is_serializable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_object2bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# capnp proto\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_type(\u001b[43mis_serializable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object2bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_bytes:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     serialized_data \u001b[38;5;241m=\u001b[39m is_serializable\u001b[38;5;241m.\u001b[39m_object2proto()\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/tensor/tensor.py:635\u001b[0m, in \u001b[0;36mTensor._object2bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# this is how we dispatch correct deserialization of bytes\u001b[39;00m\n\u001b[1;32m    633\u001b[0m tensor_msg\u001b[38;5;241m.\u001b[39mmagicHeader \u001b[38;5;241m=\u001b[39m serde_magic_header(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m--> 635\u001b[0m chunk_bytes(\u001b[43mserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchild\u001b[39m\u001b[38;5;124m\"\u001b[39m, tensor_msg)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    637\u001b[0m tensor_msg\u001b[38;5;241m.\u001b[39mpublicShape \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpublic_shape, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# upcast the String class before setting to capnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/common/serde/serialize.py:77\u001b[0m, in \u001b[0;36m_serialize\u001b[0;34m(obj, to_proto, to_bytes)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# traceback_and_raise(\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     Exception(\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#         f\"Object {type(obj)} is not serializable and has no _sy_serializable_wrapper_type\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# capnp_bytes=True\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(is_serializable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_object2bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# capnp proto\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_type(\u001b[43mis_serializable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object2bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mbytes\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_bytes:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# debug(f\"Serializing {type(is_serializable)}\")\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# indent=None means no white space or \\n in the serialized version\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# this is compatible with json.dumps(x, indent=None)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     serialized_data \u001b[38;5;241m=\u001b[39m is_serializable\u001b[38;5;241m.\u001b[39m_object2proto()\u001b[38;5;241m.\u001b[39mSerializeToString()\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/tensor/autodp/phi_tensor.py:3957\u001b[0m, in \u001b[0;36mPhiTensor._object2bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3955\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mminVals \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_vals, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3956\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mmaxVals \u001b[38;5;241m=\u001b[39m serialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_vals, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 3957\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mdataSubject \u001b[38;5;241m=\u001b[39m serialize(\u001b[43mdstonumpyutf8\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_subject\u001b[49m\u001b[43m)\u001b[49m, to_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3958\u001b[0m pt_msg\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mto_string()\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;66;03m# to pack or not to pack?\u001b[39;00m\n\u001b[1;32m   3960\u001b[0m \u001b[38;5;66;03m# to_bytes = pt_msg.to_bytes()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/syft_env/lib/python3.9/site-packages/syft/core/adp/data_subject.py:198\u001b[0m, in \u001b[0;36mdstonumpyutf8\u001b[0;34m(data_subject)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdstonumpyutf8\u001b[39m(data_subject: DataSubject) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m--> 198\u001b[0m     name_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mdata_subject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m()\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m     np_bytes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(name_bytes, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint64)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np_bytes\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_string'"
     ]
    }
   ],
   "source": [
    "domain_client.load_dataset(\n",
    "   name=\"Spiderman_Age_v2_Dataset\",\n",
    "   assets={\n",
    "       \"Age_Data\": age_data,\n",
    "   },\n",
    "   description=\"Our dataset contains the Ages of people who watched the movie Spiderman in the cinema in Moscow version 2. There are 2 columns and 11 rows in our dataset.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd56ffa9-a032-473f-bba9-477e616651ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "                #myInput {\n",
       "                  background-position: 10px 12px; /* Position the search icon */\n",
       "                  background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "                  background-color: #bbb;\n",
       "                  width: 98%; /* Full-width */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                  padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  margin-bottom: 12px; /* Add some space below the input */\n",
       "                }\n",
       "\n",
       "                #myTable {\n",
       "                  border-collapse: collapse; /* Collapse borders */\n",
       "                  width: 100%; /* Full-width */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                }\n",
       "\n",
       "                #myTable th, #myTable td {\n",
       "                  text-align: left; /* Left-align text */\n",
       "                  padding: 10px; /* Add padding */\n",
       "                }\n",
       "\n",
       "                #myTable tr {\n",
       "                  /* Add a bottom border to all table rows */\n",
       "                  border-bottom: 1px solid #ddd;\n",
       "                }\n",
       "\n",
       "                #myTable tr.header, #myTable tr:hover {\n",
       "                  /* Add a grey background color to the table header and on hover */\n",
       "                  background-color: #777;\n",
       "                }\n",
       "                </style>\n",
       "\n",
       "                <table id=\"myTable\" style=\"width:1000px\">\n",
       "                  <tr class=\"header\">\n",
       "                    <th style=\"width:30px\">Idx</th>\n",
       "                    <th style=\"width:20%;\">Name</th>\n",
       "                    <th style=\"width:35%;\">Description</th>\n",
       "                    <th style=\"width:20%;\">Assets</th>\n",
       "                    <th style=\"width:300px;\">Id</th>\n",
       "                  </tr>\n",
       "                \n",
       "\n",
       "          <tr>\n",
       "            <td>[0]</td>\n",
       "            <td>Family_Age_Dataset</td>\n",
       "            <td>Our dataset contains the Ages of our four Family members with unique ID's. There are 2 columns and 4 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br /></td>\n",
       "            <td>2515f228-3967-4b88-ae59-df697aad6518</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[1]</td>\n",
       "            <td>Spiderman_Audience_Age_Dataset</td>\n",
       "            <td>Our dataset contains the Ages of people who watched the movie Spiderman in the cinema in Moscow. There are 2 columns and 11 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br /></td>\n",
       "            <td>0969b9b9-af47-41e3-9604-4eeb9f16c4bb</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[2]</td>\n",
       "            <td>Spiderman_Age_v2_Dataset</td>\n",
       "            <td>Our dataset contains the Ages of people who watched the movie Spiderman in the cinema in Moscow version 2. There are 2 columns and 11 rows in our dataset.</td>\n",
       "            <td>[\"Age_Data\"] -> Tensor<br /><br /></td>\n",
       "            <td>d7a46e93-131e-49bb-8fb2-2b76282790af</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        <script>\n",
       "        function myFunction() {\n",
       "          // Declare variables\n",
       "          var input, filter, table, tr, td, i, txtValue;\n",
       "          input = document.getElementById(\"myInput\");\n",
       "          filter = input.value.toUpperCase();\n",
       "          table = document.getElementById(\"myTable\");\n",
       "          tr = table.getElementsByTagName(\"tr\");\n",
       "\n",
       "          // Loop through all table rows, and hide those who don't match the search query\n",
       "          for (i = 0; i < tr.length; i++) {\n",
       "            name_td = tr[i].getElementsByTagName(\"td\")[1];\n",
       "            desc_td = tr[i].getElementsByTagName(\"td\")[2];\n",
       "            asset_td = tr[i].getElementsByTagName(\"td\")[3];\n",
       "            id_td = tr[i].getElementsByTagName(\"td\")[4];\n",
       "            if (name_td || desc_td || asset_td || id_td) {\n",
       "              name_txtValue = name_td.textContent || name_td.innerText;\n",
       "              desc_txtValue = desc_td.textContent || name_td.innerText;\n",
       "              asset_txtValue = asset_td.textContent || name_td.innerText;\n",
       "              id_txtValue = id_td.textContent || name_td.innerText;\n",
       "              name_bool = name_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              desc_bool = desc_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              asset_bool = asset_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              id_bool = id_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              if (name_bool || desc_bool || asset_bool || id_bool) {\n",
       "                tr[i].style.display = \"\";\n",
       "              } else {\n",
       "                tr[i].style.display = \"none\";\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.DatasetRequestAPI at 0x7f3e09b86850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685cc553-f9f2-4b19-aeac-7f2b1f6da0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
